2025-11-16 09:55:29,197:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 09:55:29,197:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 09:55:29,197:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 09:55:29,197:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 09:56:01,264:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 09:56:01,266:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 09:56:01,266:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 09:56:01,266:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 09:59:32,093:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 09:59:32,093:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 09:59:32,093:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 09:59:32,093:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 10:02:20,472:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 10:02:20,472:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 10:02:20,472:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 10:02:20,472:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 10:02:28,497:INFO:PyCaret ClassificationExperiment
2025-11-16 10:02:28,497:INFO:Logging name: clf-default-name
2025-11-16 10:02:28,497:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-16 10:02:28,497:INFO:version 3.3.2
2025-11-16 10:02:28,497:INFO:Initializing setup()
2025-11-16 10:02:28,497:INFO:self.USI: 2efb
2025-11-16 10:02:28,497:INFO:self._variable_keys: {'gpu_n_jobs_param', 'pipeline', 'y_test', 'X_test', 'exp_id', '_ml_usecase', 'idx', 'X', 'n_jobs_param', 'logging_param', 'data', 'X_train', 'exp_name_log', 'fold_generator', 'fold_groups_param', 'is_multiclass', 'log_plots_param', '_available_plots', 'seed', 'gpu_param', 'fix_imbalance', 'USI', 'y', 'target_param', 'fold_shuffle_param', 'html_param', 'memory', 'y_train'}
2025-11-16 10:02:28,497:INFO:Checking environment
2025-11-16 10:02:28,497:INFO:python_version: 3.11.9
2025-11-16 10:02:28,497:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-11-16 10:02:28,497:INFO:machine: AMD64
2025-11-16 10:02:28,515:INFO:platform: Windows-10-10.0.26200-SP0
2025-11-16 10:02:28,515:INFO:Memory: svmem(total=16890519552, available=3511439360, percent=79.2, used=13379080192, free=3511439360)
2025-11-16 10:02:28,515:INFO:Physical Core: 10
2025-11-16 10:02:28,515:INFO:Logical Core: 16
2025-11-16 10:02:28,515:INFO:Checking libraries
2025-11-16 10:02:28,515:INFO:System:
2025-11-16 10:02:28,515:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-11-16 10:02:28,515:INFO:executable: C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Scripts\python.exe
2025-11-16 10:02:28,515:INFO:   machine: Windows-10-10.0.26200-SP0
2025-11-16 10:02:28,515:INFO:PyCaret required dependencies:
2025-11-16 10:02:28,515:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-16 10:02:28,610:INFO:                 pip: Not installed
2025-11-16 10:02:28,610:INFO:          setuptools: 80.9.0
2025-11-16 10:02:28,610:INFO:             pycaret: 3.3.2
2025-11-16 10:02:28,610:INFO:             IPython: 9.7.0
2025-11-16 10:02:28,610:INFO:          ipywidgets: 8.1.8
2025-11-16 10:02:28,610:INFO:                tqdm: 4.67.1
2025-11-16 10:02:28,610:INFO:               numpy: 1.26.4
2025-11-16 10:02:28,610:INFO:              pandas: 2.1.4
2025-11-16 10:02:28,610:INFO:              jinja2: 3.1.6
2025-11-16 10:02:28,610:INFO:               scipy: 1.11.4
2025-11-16 10:02:28,610:INFO:              joblib: 1.3.2
2025-11-16 10:02:28,610:INFO:             sklearn: 1.4.2
2025-11-16 10:02:28,610:INFO:                pyod: 2.0.5
2025-11-16 10:02:28,610:INFO:            imblearn: 0.14.0
2025-11-16 10:02:28,610:INFO:   category_encoders: 2.7.0
2025-11-16 10:02:28,610:INFO:            lightgbm: 4.6.0
2025-11-16 10:02:28,610:INFO:               numba: 0.62.1
2025-11-16 10:02:28,610:INFO:            requests: 2.32.5
2025-11-16 10:02:28,610:INFO:          matplotlib: 3.7.5
2025-11-16 10:02:28,610:INFO:          scikitplot: 0.3.7
2025-11-16 10:02:28,610:INFO:         yellowbrick: 1.5
2025-11-16 10:02:28,610:INFO:              plotly: 5.24.1
2025-11-16 10:02:28,610:INFO:    plotly-resampler: Not installed
2025-11-16 10:02:28,610:INFO:             kaleido: 1.2.0
2025-11-16 10:02:28,610:INFO:           schemdraw: 0.15
2025-11-16 10:02:28,610:INFO:         statsmodels: 0.14.5
2025-11-16 10:02:28,610:INFO:              sktime: 0.26.0
2025-11-16 10:02:28,610:INFO:               tbats: 1.1.3
2025-11-16 10:02:28,610:INFO:            pmdarima: 2.0.4
2025-11-16 10:02:28,610:INFO:              psutil: 7.1.3
2025-11-16 10:02:28,610:INFO:          markupsafe: 3.0.3
2025-11-16 10:02:28,610:INFO:             pickle5: Not installed
2025-11-16 10:02:28,610:INFO:         cloudpickle: 3.1.2
2025-11-16 10:02:28,610:INFO:         deprecation: 2.1.0
2025-11-16 10:02:28,610:INFO:              xxhash: 3.6.0
2025-11-16 10:02:28,610:INFO:           wurlitzer: Not installed
2025-11-16 10:02:28,610:INFO:PyCaret optional dependencies:
2025-11-16 10:02:28,610:INFO:                shap: Not installed
2025-11-16 10:02:28,610:INFO:           interpret: Not installed
2025-11-16 10:02:28,610:INFO:                umap: Not installed
2025-11-16 10:02:28,610:INFO:     ydata_profiling: Not installed
2025-11-16 10:02:28,610:INFO:  explainerdashboard: Not installed
2025-11-16 10:02:28,610:INFO:             autoviz: Not installed
2025-11-16 10:02:28,610:INFO:           fairlearn: Not installed
2025-11-16 10:02:28,610:INFO:          deepchecks: Not installed
2025-11-16 10:02:28,610:INFO:             xgboost: Not installed
2025-11-16 10:02:28,610:INFO:            catboost: Not installed
2025-11-16 10:02:28,610:INFO:              kmodes: Not installed
2025-11-16 10:02:28,610:INFO:             mlxtend: Not installed
2025-11-16 10:02:28,610:INFO:       statsforecast: Not installed
2025-11-16 10:02:28,610:INFO:        tune_sklearn: Not installed
2025-11-16 10:02:28,610:INFO:                 ray: Not installed
2025-11-16 10:02:28,610:INFO:            hyperopt: Not installed
2025-11-16 10:02:28,610:INFO:              optuna: Not installed
2025-11-16 10:02:28,610:INFO:               skopt: Not installed
2025-11-16 10:02:28,610:INFO:              mlflow: Not installed
2025-11-16 10:02:28,610:INFO:              gradio: Not installed
2025-11-16 10:02:28,610:INFO:             fastapi: Not installed
2025-11-16 10:02:28,610:INFO:             uvicorn: Not installed
2025-11-16 10:02:28,610:INFO:              m2cgen: Not installed
2025-11-16 10:02:28,610:INFO:           evidently: Not installed
2025-11-16 10:02:28,610:INFO:               fugue: Not installed
2025-11-16 10:02:28,610:INFO:           streamlit: Not installed
2025-11-16 10:02:28,610:INFO:             prophet: Not installed
2025-11-16 10:02:28,610:INFO:None
2025-11-16 10:02:28,610:INFO:Set up data.
2025-11-16 10:02:28,621:INFO:Set up folding strategy.
2025-11-16 10:02:28,621:INFO:Set up train/test split.
2025-11-16 10:02:28,654:INFO:Set up index.
2025-11-16 10:02:28,655:INFO:Assigning column types.
2025-11-16 10:02:28,655:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-16 10:02:28,677:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-16 10:02:28,677:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-16 10:02:28,709:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 10:02:28,709:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 10:02:28,725:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-16 10:02:28,725:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-16 10:02:28,740:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 10:02:28,740:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 10:02:28,740:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-16 10:02:28,756:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-16 10:02:28,775:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 10:02:28,775:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 10:02:28,788:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-16 10:02:28,808:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 10:02:28,808:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 10:02:28,808:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-16 10:02:28,838:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 10:02:28,838:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 10:02:28,876:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 10:02:28,876:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 10:02:28,876:INFO:Preparing preprocessing pipeline...
2025-11-16 10:02:28,876:INFO:Set up label encoding.
2025-11-16 10:02:28,876:INFO:Set up simple imputation.
2025-11-16 10:02:28,881:INFO:Finished creating preprocessing pipeline.
2025-11-16 10:02:28,892:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lamaq\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['sepal_length', 'sepal_width',
                                             'petal_length', 'petal_width'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-11-16 10:02:28,892:INFO:Creating final display dataframe.
2025-11-16 10:02:28,908:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                                 42
1                        Target                                            species
2                   Target type                                         Multiclass
3                Target mapping  Iris-setosa: 0, Iris-versicolor: 1, Iris-virgi...
4           Original data shape                                           (150, 5)
5        Transformed data shape                                           (150, 5)
6   Transformed train set shape                                           (105, 5)
7    Transformed test set shape                                            (45, 5)
8              Numeric features                                                  4
9                    Preprocess                                               True
10              Imputation type                                             simple
11           Numeric imputation                                               mean
12       Categorical imputation                                               mode
13               Fold Generator                                    StratifiedKFold
14                  Fold Number                                                 10
15                     CPU Jobs                                                 -1
16                      Use GPU                                              False
17               Log Experiment                                              False
18              Experiment Name                                   clf-default-name
19                          USI                                               2efb
2025-11-16 10:02:28,956:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 10:02:28,956:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 10:02:28,986:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 10:02:28,986:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 10:02:28,986:INFO:setup() successfully completed in 0.49s...............
2025-11-16 10:02:28,986:INFO:Initializing compare_models()
2025-11-16 10:02:28,986:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000215289C9610>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000215289C9610>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-11-16 10:02:28,986:INFO:Checking exceptions
2025-11-16 10:02:28,986:INFO:Preparing display monitor
2025-11-16 10:02:28,986:INFO:Initializing Logistic Regression
2025-11-16 10:02:28,986:INFO:Total runtime is 0.0 minutes
2025-11-16 10:02:28,986:INFO:SubProcess create_model() called ==================================
2025-11-16 10:02:28,986:INFO:Initializing create_model()
2025-11-16 10:02:28,986:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000215289C9610>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021572F17390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 10:02:28,986:INFO:Checking exceptions
2025-11-16 10:02:28,986:INFO:Importing libraries
2025-11-16 10:02:28,986:INFO:Copying training dataset
2025-11-16 10:02:28,986:INFO:Defining folds
2025-11-16 10:02:28,986:INFO:Declaring metric variables
2025-11-16 10:02:28,997:INFO:Importing untrained model
2025-11-16 10:02:28,997:INFO:Logistic Regression Imported successfully
2025-11-16 10:02:28,997:INFO:Starting cross validation
2025-11-16 10:02:28,997:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 10:02:31,676:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-16 10:02:31,678:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-16 10:02:31,678:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-16 10:02:31,707:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-16 10:02:31,721:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-16 10:02:31,721:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-16 10:02:31,730:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-16 10:02:31,731:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-16 10:02:31,758:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-16 10:02:31,768:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-16 10:02:31,878:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:31,878:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:31,881:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,881:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:31,881:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,881:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,881:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,881:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,881:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,881:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,881:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,881:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,892:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:31,892:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,892:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,892:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,912:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:31,914:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,916:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,920:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:31,921:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,921:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,923:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,925:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,929:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:31,931:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,933:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,933:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,943:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:31,946:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,948:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,952:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,954:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:31,956:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,958:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,960:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,968:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:31,968:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,968:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,974:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:31,985:INFO:Calculating mean and std
2025-11-16 10:02:31,985:INFO:Creating metrics dataframe
2025-11-16 10:02:31,987:INFO:Uploading results into container
2025-11-16 10:02:31,987:INFO:Uploading model into container now
2025-11-16 10:02:31,987:INFO:_master_model_container: 1
2025-11-16 10:02:31,987:INFO:_display_container: 2
2025-11-16 10:02:31,987:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-16 10:02:31,987:INFO:create_model() successfully completed......................................
2025-11-16 10:02:32,033:INFO:SubProcess create_model() end ==================================
2025-11-16 10:02:32,033:INFO:Creating metrics dataframe
2025-11-16 10:02:32,033:INFO:Initializing K Neighbors Classifier
2025-11-16 10:02:32,033:INFO:Total runtime is 0.05077218214670817 minutes
2025-11-16 10:02:32,033:INFO:SubProcess create_model() called ==================================
2025-11-16 10:02:32,033:INFO:Initializing create_model()
2025-11-16 10:02:32,033:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000215289C9610>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021572F17390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 10:02:32,033:INFO:Checking exceptions
2025-11-16 10:02:32,033:INFO:Importing libraries
2025-11-16 10:02:32,033:INFO:Copying training dataset
2025-11-16 10:02:32,033:INFO:Defining folds
2025-11-16 10:02:32,033:INFO:Declaring metric variables
2025-11-16 10:02:32,033:INFO:Importing untrained model
2025-11-16 10:02:32,033:INFO:K Neighbors Classifier Imported successfully
2025-11-16 10:02:32,033:INFO:Starting cross validation
2025-11-16 10:02:32,033:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 10:02:32,104:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:32,104:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:32,108:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:32,108:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:32,110:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:32,110:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:32,110:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:32,110:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:32,110:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:32,110:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:32,110:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:33,756:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-16 10:02:33,763:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-16 10:02:33,765:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-16 10:02:33,774:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-16 10:02:33,774:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-16 10:02:33,774:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-16 10:02:33,934:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:33,937:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:33,937:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:33,941:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:33,942:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:33,944:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:33,945:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:33,945:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:33,947:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:33,947:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:33,949:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:33,949:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:33,951:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:33,953:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:33,953:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:33,955:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:33,955:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:33,955:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:33,965:INFO:Calculating mean and std
2025-11-16 10:02:33,965:INFO:Creating metrics dataframe
2025-11-16 10:02:33,967:INFO:Uploading results into container
2025-11-16 10:02:33,969:INFO:Uploading model into container now
2025-11-16 10:02:33,969:INFO:_master_model_container: 2
2025-11-16 10:02:33,969:INFO:_display_container: 2
2025-11-16 10:02:33,969:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-16 10:02:33,969:INFO:create_model() successfully completed......................................
2025-11-16 10:02:34,035:INFO:SubProcess create_model() end ==================================
2025-11-16 10:02:34,035:INFO:Creating metrics dataframe
2025-11-16 10:02:34,037:INFO:Initializing Naive Bayes
2025-11-16 10:02:34,037:INFO:Total runtime is 0.08417499860127767 minutes
2025-11-16 10:02:34,037:INFO:SubProcess create_model() called ==================================
2025-11-16 10:02:34,037:INFO:Initializing create_model()
2025-11-16 10:02:34,037:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000215289C9610>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021572F17390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 10:02:34,037:INFO:Checking exceptions
2025-11-16 10:02:34,037:INFO:Importing libraries
2025-11-16 10:02:34,037:INFO:Copying training dataset
2025-11-16 10:02:34,039:INFO:Defining folds
2025-11-16 10:02:34,039:INFO:Declaring metric variables
2025-11-16 10:02:34,039:INFO:Importing untrained model
2025-11-16 10:02:34,039:INFO:Naive Bayes Imported successfully
2025-11-16 10:02:34,039:INFO:Starting cross validation
2025-11-16 10:02:34,039:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 10:02:34,060:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,060:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,061:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,061:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,063:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,063:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,063:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,063:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,064:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,064:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,064:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,064:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,066:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,066:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,066:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,068:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,068:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,068:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,068:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,070:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,070:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,070:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,070:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,070:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,070:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,070:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,072:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,072:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,072:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,074:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,084:INFO:Calculating mean and std
2025-11-16 10:02:34,084:INFO:Creating metrics dataframe
2025-11-16 10:02:34,084:INFO:Uploading results into container
2025-11-16 10:02:34,084:INFO:Uploading model into container now
2025-11-16 10:02:34,084:INFO:_master_model_container: 3
2025-11-16 10:02:34,084:INFO:_display_container: 2
2025-11-16 10:02:34,084:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-11-16 10:02:34,084:INFO:create_model() successfully completed......................................
2025-11-16 10:02:34,126:INFO:SubProcess create_model() end ==================================
2025-11-16 10:02:34,126:INFO:Creating metrics dataframe
2025-11-16 10:02:34,126:INFO:Initializing Decision Tree Classifier
2025-11-16 10:02:34,126:INFO:Total runtime is 0.08566082715988159 minutes
2025-11-16 10:02:34,126:INFO:SubProcess create_model() called ==================================
2025-11-16 10:02:34,126:INFO:Initializing create_model()
2025-11-16 10:02:34,126:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000215289C9610>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021572F17390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 10:02:34,126:INFO:Checking exceptions
2025-11-16 10:02:34,126:INFO:Importing libraries
2025-11-16 10:02:34,126:INFO:Copying training dataset
2025-11-16 10:02:34,126:INFO:Defining folds
2025-11-16 10:02:34,126:INFO:Declaring metric variables
2025-11-16 10:02:34,126:INFO:Importing untrained model
2025-11-16 10:02:34,126:INFO:Decision Tree Classifier Imported successfully
2025-11-16 10:02:34,126:INFO:Starting cross validation
2025-11-16 10:02:34,126:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 10:02:34,154:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,154:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,154:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,156:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,156:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,156:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,156:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,158:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,158:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,158:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,158:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,158:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,160:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,160:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,161:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,161:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,161:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,161:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,161:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,165:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,165:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,165:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,167:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,167:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,167:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,167:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,169:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,171:INFO:Calculating mean and std
2025-11-16 10:02:34,171:INFO:Creating metrics dataframe
2025-11-16 10:02:34,171:INFO:Uploading results into container
2025-11-16 10:02:34,171:INFO:Uploading model into container now
2025-11-16 10:02:34,171:INFO:_master_model_container: 4
2025-11-16 10:02:34,171:INFO:_display_container: 2
2025-11-16 10:02:34,171:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-11-16 10:02:34,171:INFO:create_model() successfully completed......................................
2025-11-16 10:02:34,214:INFO:SubProcess create_model() end ==================================
2025-11-16 10:02:34,214:INFO:Creating metrics dataframe
2025-11-16 10:02:34,214:INFO:Initializing SVM - Linear Kernel
2025-11-16 10:02:34,214:INFO:Total runtime is 0.08713478247324626 minutes
2025-11-16 10:02:34,214:INFO:SubProcess create_model() called ==================================
2025-11-16 10:02:34,214:INFO:Initializing create_model()
2025-11-16 10:02:34,214:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000215289C9610>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021572F17390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 10:02:34,214:INFO:Checking exceptions
2025-11-16 10:02:34,214:INFO:Importing libraries
2025-11-16 10:02:34,214:INFO:Copying training dataset
2025-11-16 10:02:34,214:INFO:Defining folds
2025-11-16 10:02:34,214:INFO:Declaring metric variables
2025-11-16 10:02:34,214:INFO:Importing untrained model
2025-11-16 10:02:34,214:INFO:SVM - Linear Kernel Imported successfully
2025-11-16 10:02:34,214:INFO:Starting cross validation
2025-11-16 10:02:34,214:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 10:02:34,255:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,257:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,258:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,260:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,261:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,262:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,266:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,266:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,266:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,267:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,267:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,267:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,267:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,267:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,270:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,270:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,270:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,270:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-16 10:02:34,270:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,270:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,270:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,272:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,272:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,272:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,272:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,272:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,272:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,272:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,272:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,274:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,274:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,274:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,274:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,274:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,274:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,276:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,276:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,277:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,277:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,287:INFO:Calculating mean and std
2025-11-16 10:02:34,287:INFO:Creating metrics dataframe
2025-11-16 10:02:34,287:INFO:Uploading results into container
2025-11-16 10:02:34,287:INFO:Uploading model into container now
2025-11-16 10:02:34,287:INFO:_master_model_container: 5
2025-11-16 10:02:34,287:INFO:_display_container: 2
2025-11-16 10:02:34,287:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-11-16 10:02:34,287:INFO:create_model() successfully completed......................................
2025-11-16 10:02:34,318:INFO:SubProcess create_model() end ==================================
2025-11-16 10:02:34,318:INFO:Creating metrics dataframe
2025-11-16 10:02:34,334:INFO:Initializing Ridge Classifier
2025-11-16 10:02:34,334:INFO:Total runtime is 0.08912319739659627 minutes
2025-11-16 10:02:34,334:INFO:SubProcess create_model() called ==================================
2025-11-16 10:02:34,334:INFO:Initializing create_model()
2025-11-16 10:02:34,334:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000215289C9610>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021572F17390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 10:02:34,334:INFO:Checking exceptions
2025-11-16 10:02:34,334:INFO:Importing libraries
2025-11-16 10:02:34,334:INFO:Copying training dataset
2025-11-16 10:02:34,334:INFO:Defining folds
2025-11-16 10:02:34,334:INFO:Declaring metric variables
2025-11-16 10:02:34,334:INFO:Importing untrained model
2025-11-16 10:02:34,334:INFO:Ridge Classifier Imported successfully
2025-11-16 10:02:34,334:INFO:Starting cross validation
2025-11-16 10:02:34,334:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 10:02:34,353:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,354:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,354:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,354:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,356:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,356:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,358:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,359:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,359:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,362:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,362:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,362:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,364:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,364:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,364:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,364:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,364:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,364:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,366:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,366:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,366:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,366:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,366:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,366:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,366:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,366:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,366:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,366:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,366:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,366:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,366:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,366:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,366:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,366:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,366:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,366:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,366:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,366:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,366:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,373:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,383:INFO:Calculating mean and std
2025-11-16 10:02:34,383:INFO:Creating metrics dataframe
2025-11-16 10:02:34,383:INFO:Uploading results into container
2025-11-16 10:02:34,383:INFO:Uploading model into container now
2025-11-16 10:02:34,383:INFO:_master_model_container: 6
2025-11-16 10:02:34,383:INFO:_display_container: 2
2025-11-16 10:02:34,385:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-11-16 10:02:34,385:INFO:create_model() successfully completed......................................
2025-11-16 10:02:34,431:INFO:SubProcess create_model() end ==================================
2025-11-16 10:02:34,431:INFO:Creating metrics dataframe
2025-11-16 10:02:34,433:INFO:Initializing Random Forest Classifier
2025-11-16 10:02:34,433:INFO:Total runtime is 0.09078173637390137 minutes
2025-11-16 10:02:34,433:INFO:SubProcess create_model() called ==================================
2025-11-16 10:02:34,433:INFO:Initializing create_model()
2025-11-16 10:02:34,433:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000215289C9610>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021572F17390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 10:02:34,433:INFO:Checking exceptions
2025-11-16 10:02:34,433:INFO:Importing libraries
2025-11-16 10:02:34,433:INFO:Copying training dataset
2025-11-16 10:02:34,435:INFO:Defining folds
2025-11-16 10:02:34,435:INFO:Declaring metric variables
2025-11-16 10:02:34,435:INFO:Importing untrained model
2025-11-16 10:02:34,435:INFO:Random Forest Classifier Imported successfully
2025-11-16 10:02:34,435:INFO:Starting cross validation
2025-11-16 10:02:34,435:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 10:02:34,618:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,626:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,628:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,631:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,634:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,634:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,635:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,635:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,635:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,637:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,637:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,638:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,638:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,639:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,639:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,642:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,642:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,642:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,645:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,645:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,645:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,650:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,650:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,650:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,654:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,654:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,657:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,657:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,659:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,659:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,669:INFO:Calculating mean and std
2025-11-16 10:02:34,669:INFO:Creating metrics dataframe
2025-11-16 10:02:34,669:INFO:Uploading results into container
2025-11-16 10:02:34,669:INFO:Uploading model into container now
2025-11-16 10:02:34,669:INFO:_master_model_container: 7
2025-11-16 10:02:34,669:INFO:_display_container: 2
2025-11-16 10:02:34,669:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-11-16 10:02:34,669:INFO:create_model() successfully completed......................................
2025-11-16 10:02:34,713:INFO:SubProcess create_model() end ==================================
2025-11-16 10:02:34,713:INFO:Creating metrics dataframe
2025-11-16 10:02:34,713:INFO:Initializing Quadratic Discriminant Analysis
2025-11-16 10:02:34,713:INFO:Total runtime is 0.09545126756032309 minutes
2025-11-16 10:02:34,713:INFO:SubProcess create_model() called ==================================
2025-11-16 10:02:34,718:INFO:Initializing create_model()
2025-11-16 10:02:34,718:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000215289C9610>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021572F17390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 10:02:34,718:INFO:Checking exceptions
2025-11-16 10:02:34,718:INFO:Importing libraries
2025-11-16 10:02:34,718:INFO:Copying training dataset
2025-11-16 10:02:34,718:INFO:Defining folds
2025-11-16 10:02:34,718:INFO:Declaring metric variables
2025-11-16 10:02:34,718:INFO:Importing untrained model
2025-11-16 10:02:34,718:INFO:Quadratic Discriminant Analysis Imported successfully
2025-11-16 10:02:34,718:INFO:Starting cross validation
2025-11-16 10:02:34,718:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 10:02:34,745:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,745:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,745:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,747:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,747:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,747:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,747:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,747:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,747:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,747:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,747:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,747:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,747:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,747:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,747:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,747:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,750:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,750:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,750:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,750:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,750:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,750:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,750:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,750:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,750:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,750:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,750:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,752:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,752:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,752:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,752:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,752:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,752:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,752:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,752:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,752:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,752:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,755:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,755:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,765:INFO:Calculating mean and std
2025-11-16 10:02:34,765:INFO:Creating metrics dataframe
2025-11-16 10:02:34,765:INFO:Uploading results into container
2025-11-16 10:02:34,765:INFO:Uploading model into container now
2025-11-16 10:02:34,765:INFO:_master_model_container: 8
2025-11-16 10:02:34,765:INFO:_display_container: 2
2025-11-16 10:02:34,767:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-11-16 10:02:34,767:INFO:create_model() successfully completed......................................
2025-11-16 10:02:34,809:INFO:SubProcess create_model() end ==================================
2025-11-16 10:02:34,809:INFO:Creating metrics dataframe
2025-11-16 10:02:34,809:INFO:Initializing Ada Boost Classifier
2025-11-16 10:02:34,809:INFO:Total runtime is 0.0970416267712911 minutes
2025-11-16 10:02:34,809:INFO:SubProcess create_model() called ==================================
2025-11-16 10:02:34,809:INFO:Initializing create_model()
2025-11-16 10:02:34,809:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000215289C9610>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021572F17390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 10:02:34,809:INFO:Checking exceptions
2025-11-16 10:02:34,809:INFO:Importing libraries
2025-11-16 10:02:34,809:INFO:Copying training dataset
2025-11-16 10:02:34,809:INFO:Defining folds
2025-11-16 10:02:34,809:INFO:Declaring metric variables
2025-11-16 10:02:34,809:INFO:Importing untrained model
2025-11-16 10:02:34,809:INFO:Ada Boost Classifier Imported successfully
2025-11-16 10:02:34,809:INFO:Starting cross validation
2025-11-16 10:02:34,809:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 10:02:34,824:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 10:02:34,824:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 10:02:34,826:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 10:02:34,826:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 10:02:34,828:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 10:02:34,829:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 10:02:34,834:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 10:02:34,836:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 10:02:34,838:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 10:02:34,840:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 10:02:34,877:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,879:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,881:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,881:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,889:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,889:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,891:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,891:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,891:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,891:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,893:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,893:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,893:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,895:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,895:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,895:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,897:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,897:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,897:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,897:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,899:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,899:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,901:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,901:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,901:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,903:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,903:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,903:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,903:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,903:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,903:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,903:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,903:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,907:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,907:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,907:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,913:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:34,915:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,915:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,917:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:34,924:INFO:Calculating mean and std
2025-11-16 10:02:34,924:INFO:Creating metrics dataframe
2025-11-16 10:02:34,924:INFO:Uploading results into container
2025-11-16 10:02:34,924:INFO:Uploading model into container now
2025-11-16 10:02:34,924:INFO:_master_model_container: 9
2025-11-16 10:02:34,924:INFO:_display_container: 2
2025-11-16 10:02:34,924:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-11-16 10:02:34,924:INFO:create_model() successfully completed......................................
2025-11-16 10:02:34,962:INFO:SubProcess create_model() end ==================================
2025-11-16 10:02:34,962:INFO:Creating metrics dataframe
2025-11-16 10:02:34,962:INFO:Initializing Gradient Boosting Classifier
2025-11-16 10:02:34,962:INFO:Total runtime is 0.09960459073384603 minutes
2025-11-16 10:02:34,962:INFO:SubProcess create_model() called ==================================
2025-11-16 10:02:34,962:INFO:Initializing create_model()
2025-11-16 10:02:34,962:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000215289C9610>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021572F17390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 10:02:34,962:INFO:Checking exceptions
2025-11-16 10:02:34,962:INFO:Importing libraries
2025-11-16 10:02:34,962:INFO:Copying training dataset
2025-11-16 10:02:34,962:INFO:Defining folds
2025-11-16 10:02:34,962:INFO:Declaring metric variables
2025-11-16 10:02:34,962:INFO:Importing untrained model
2025-11-16 10:02:34,962:INFO:Gradient Boosting Classifier Imported successfully
2025-11-16 10:02:34,962:INFO:Starting cross validation
2025-11-16 10:02:34,962:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 10:02:35,123:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:35,125:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,125:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:35,125:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,125:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,127:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,127:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:35,127:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,127:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,129:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,129:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,131:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,153:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:35,153:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:35,156:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,156:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,158:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,158:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,158:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,162:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,162:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:35,162:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,164:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,166:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,188:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:35,188:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,190:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,190:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,199:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:35,200:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,200:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:35,200:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,200:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,200:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,202:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,202:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,205:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:35,205:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,207:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,207:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,215:INFO:Calculating mean and std
2025-11-16 10:02:35,216:INFO:Creating metrics dataframe
2025-11-16 10:02:35,216:INFO:Uploading results into container
2025-11-16 10:02:35,216:INFO:Uploading model into container now
2025-11-16 10:02:35,216:INFO:_master_model_container: 10
2025-11-16 10:02:35,216:INFO:_display_container: 2
2025-11-16 10:02:35,216:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-16 10:02:35,216:INFO:create_model() successfully completed......................................
2025-11-16 10:02:35,261:INFO:SubProcess create_model() end ==================================
2025-11-16 10:02:35,261:INFO:Creating metrics dataframe
2025-11-16 10:02:35,261:INFO:Initializing Linear Discriminant Analysis
2025-11-16 10:02:35,261:INFO:Total runtime is 0.10457674662272136 minutes
2025-11-16 10:02:35,261:INFO:SubProcess create_model() called ==================================
2025-11-16 10:02:35,261:INFO:Initializing create_model()
2025-11-16 10:02:35,261:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000215289C9610>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021572F17390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 10:02:35,261:INFO:Checking exceptions
2025-11-16 10:02:35,261:INFO:Importing libraries
2025-11-16 10:02:35,261:INFO:Copying training dataset
2025-11-16 10:02:35,261:INFO:Defining folds
2025-11-16 10:02:35,261:INFO:Declaring metric variables
2025-11-16 10:02:35,261:INFO:Importing untrained model
2025-11-16 10:02:35,261:INFO:Linear Discriminant Analysis Imported successfully
2025-11-16 10:02:35,261:INFO:Starting cross validation
2025-11-16 10:02:35,261:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 10:02:35,281:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:35,281:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,283:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:35,283:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,283:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,283:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:35,285:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,285:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:35,285:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:35,285:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,285:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:35,285:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,285:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,285:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,285:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,287:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,287:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,287:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,287:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,287:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,287:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,287:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,289:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,289:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,293:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:35,293:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:35,293:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,295:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,295:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:35,295:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,295:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,295:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,295:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-11-16 10:02:35,298:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,298:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,298:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,298:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,298:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,298:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,300:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,306:INFO:Calculating mean and std
2025-11-16 10:02:35,306:INFO:Creating metrics dataframe
2025-11-16 10:02:35,306:INFO:Uploading results into container
2025-11-16 10:02:35,306:INFO:Uploading model into container now
2025-11-16 10:02:35,306:INFO:_master_model_container: 11
2025-11-16 10:02:35,306:INFO:_display_container: 2
2025-11-16 10:02:35,306:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-11-16 10:02:35,306:INFO:create_model() successfully completed......................................
2025-11-16 10:02:35,348:INFO:SubProcess create_model() end ==================================
2025-11-16 10:02:35,348:INFO:Creating metrics dataframe
2025-11-16 10:02:35,348:INFO:Initializing Extra Trees Classifier
2025-11-16 10:02:35,348:INFO:Total runtime is 0.1060323158899943 minutes
2025-11-16 10:02:35,348:INFO:SubProcess create_model() called ==================================
2025-11-16 10:02:35,348:INFO:Initializing create_model()
2025-11-16 10:02:35,348:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000215289C9610>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021572F17390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 10:02:35,348:INFO:Checking exceptions
2025-11-16 10:02:35,348:INFO:Importing libraries
2025-11-16 10:02:35,348:INFO:Copying training dataset
2025-11-16 10:02:35,348:INFO:Defining folds
2025-11-16 10:02:35,348:INFO:Declaring metric variables
2025-11-16 10:02:35,348:INFO:Importing untrained model
2025-11-16 10:02:35,348:INFO:Extra Trees Classifier Imported successfully
2025-11-16 10:02:35,348:INFO:Starting cross validation
2025-11-16 10:02:35,348:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 10:02:35,517:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,520:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,520:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,520:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,524:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,524:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,524:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,524:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,527:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,527:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,527:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,529:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,529:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,529:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,531:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,531:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,533:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,533:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,538:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,540:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,540:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,540:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,540:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,540:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,540:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,540:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,540:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,540:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,546:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,547:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:35,558:INFO:Calculating mean and std
2025-11-16 10:02:35,558:INFO:Creating metrics dataframe
2025-11-16 10:02:35,558:INFO:Uploading results into container
2025-11-16 10:02:35,558:INFO:Uploading model into container now
2025-11-16 10:02:35,558:INFO:_master_model_container: 12
2025-11-16 10:02:35,558:INFO:_display_container: 2
2025-11-16 10:02:35,558:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-11-16 10:02:35,558:INFO:create_model() successfully completed......................................
2025-11-16 10:02:35,604:INFO:SubProcess create_model() end ==================================
2025-11-16 10:02:35,604:INFO:Creating metrics dataframe
2025-11-16 10:02:35,604:INFO:Initializing Light Gradient Boosting Machine
2025-11-16 10:02:35,604:INFO:Total runtime is 0.11029642820358276 minutes
2025-11-16 10:02:35,606:INFO:SubProcess create_model() called ==================================
2025-11-16 10:02:35,606:INFO:Initializing create_model()
2025-11-16 10:02:35,606:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000215289C9610>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021572F17390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 10:02:35,606:INFO:Checking exceptions
2025-11-16 10:02:35,606:INFO:Importing libraries
2025-11-16 10:02:35,606:INFO:Copying training dataset
2025-11-16 10:02:35,606:INFO:Defining folds
2025-11-16 10:02:35,606:INFO:Declaring metric variables
2025-11-16 10:02:35,606:INFO:Importing untrained model
2025-11-16 10:02:35,606:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-16 10:02:35,606:INFO:Starting cross validation
2025-11-16 10:02:35,606:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 10:02:36,077:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,079:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,080:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,126:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,129:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,130:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,133:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,137:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,137:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,139:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,139:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,140:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,158:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,161:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,163:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,163:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,166:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,168:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,168:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,170:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,174:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,192:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,195:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,195:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,197:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,197:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,200:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,208:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,210:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,213:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,226:INFO:Calculating mean and std
2025-11-16 10:02:36,226:INFO:Creating metrics dataframe
2025-11-16 10:02:36,229:INFO:Uploading results into container
2025-11-16 10:02:36,229:INFO:Uploading model into container now
2025-11-16 10:02:36,230:INFO:_master_model_container: 13
2025-11-16 10:02:36,230:INFO:_display_container: 2
2025-11-16 10:02:36,230:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-16 10:02:36,230:INFO:create_model() successfully completed......................................
2025-11-16 10:02:36,290:INFO:SubProcess create_model() end ==================================
2025-11-16 10:02:36,290:INFO:Creating metrics dataframe
2025-11-16 10:02:36,294:INFO:Initializing Dummy Classifier
2025-11-16 10:02:36,294:INFO:Total runtime is 0.1217947006225586 minutes
2025-11-16 10:02:36,294:INFO:SubProcess create_model() called ==================================
2025-11-16 10:02:36,294:INFO:Initializing create_model()
2025-11-16 10:02:36,294:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000215289C9610>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021572F17390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 10:02:36,294:INFO:Checking exceptions
2025-11-16 10:02:36,294:INFO:Importing libraries
2025-11-16 10:02:36,294:INFO:Copying training dataset
2025-11-16 10:02:36,296:INFO:Defining folds
2025-11-16 10:02:36,296:INFO:Declaring metric variables
2025-11-16 10:02:36,296:INFO:Importing untrained model
2025-11-16 10:02:36,296:INFO:Dummy Classifier Imported successfully
2025-11-16 10:02:36,297:INFO:Starting cross validation
2025-11-16 10:02:36,297:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 10:02:36,315:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,315:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,315:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,315:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,315:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,317:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,317:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,317:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-16 10:02:36,317:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,317:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-16 10:02:36,317:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,317:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,317:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-16 10:02:36,319:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,319:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-16 10:02:36,319:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,319:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,319:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,319:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,319:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-16 10:02:36,321:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,321:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-16 10:02:36,321:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,321:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,321:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,323:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,323:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,323:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,323:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-16 10:02:36,323:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,323:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,323:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,323:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,323:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,327:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-16 10:02:36,327:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-16 10:02:36,327:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,327:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,327:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 10:02:36,334:INFO:Calculating mean and std
2025-11-16 10:02:36,334:INFO:Creating metrics dataframe
2025-11-16 10:02:36,335:INFO:Uploading results into container
2025-11-16 10:02:36,335:INFO:Uploading model into container now
2025-11-16 10:02:36,335:INFO:_master_model_container: 14
2025-11-16 10:02:36,335:INFO:_display_container: 2
2025-11-16 10:02:36,335:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-11-16 10:02:36,335:INFO:create_model() successfully completed......................................
2025-11-16 10:02:36,385:INFO:SubProcess create_model() end ==================================
2025-11-16 10:02:36,385:INFO:Creating metrics dataframe
2025-11-16 10:02:36,387:WARNING:C:\Users\lamaq\OneDrive\Desktop\Devops\Exp10\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-11-16 10:02:36,387:INFO:Initializing create_model()
2025-11-16 10:02:36,387:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000215289C9610>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 10:02:36,387:INFO:Checking exceptions
2025-11-16 10:02:36,387:INFO:Importing libraries
2025-11-16 10:02:36,387:INFO:Copying training dataset
2025-11-16 10:02:36,389:INFO:Defining folds
2025-11-16 10:02:36,389:INFO:Declaring metric variables
2025-11-16 10:02:36,389:INFO:Importing untrained model
2025-11-16 10:02:36,389:INFO:Declaring custom model
2025-11-16 10:02:36,389:INFO:Quadratic Discriminant Analysis Imported successfully
2025-11-16 10:02:36,389:INFO:Cross validation set to False
2025-11-16 10:02:36,390:INFO:Fitting Model
2025-11-16 10:02:36,392:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-11-16 10:02:36,392:INFO:create_model() successfully completed......................................
2025-11-16 10:02:36,442:INFO:_master_model_container: 14
2025-11-16 10:02:36,442:INFO:_display_container: 2
2025-11-16 10:02:36,442:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-11-16 10:02:36,442:INFO:compare_models() successfully completed......................................
{'timestamp': '2025-11-16T04:36:45.204837', 'input': [5.1, 3.5, 1.4, 0.2], 'prediction': '0'}
